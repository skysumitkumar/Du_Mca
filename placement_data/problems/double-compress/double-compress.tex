Brown Lobstah, Inc.\  owns 2,000 restaurants all over the world, and their
sales reports are transferred every day to its headquarters in Cranston
via secure telephone lines.  To reduce communication costs, the CEO
had asked a computer consultant to give her some advice. The consultant
said:

\begin{quote}
	``Oh! that's easy, you can request the branches to compress their
	reports using Huffman encoding before transmission.''
\end{quote}

They did so and communication costs were reduced.  But an ambitious
programmer now tells the CEO:

\begin{quote}
	``Hey! Huffman compression is pretty good!  Why don't we compress the
	data {\em twice\/}! I mean, if we treat the encoded text as a sequence
	of 8-bit characters, then we can apply the Huffman algorithm again on
	those 8-bit characters to get even smaller data size!  Actually, how
	about compressing the data {\em multiple times\/}?  The data size will
	get smaller and smaller!''
\end{quote}

Is the programmer right?   Can any data be arbitrarily reduced in
size by repeated applications of Huffman encoding?

{\em Hint:} View an encoding algorithm as a one-to-one function $f$
that maps a binary string $x$ into another binary string $y=f(x)$.  Can such
a function reduce the size of all strings, i.e., is it possible that
$y$ is always shorter than $x$?  Remember that $f$ is one-to-one,
i.e., $f(x_1) =f(x_2) \Longrightarrow  x_1 = x_2$.

