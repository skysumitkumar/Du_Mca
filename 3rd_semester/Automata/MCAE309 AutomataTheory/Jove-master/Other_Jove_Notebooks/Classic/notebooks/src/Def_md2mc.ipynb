{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# A markdown for machines\n",
    "\n",
    "One of the purposes of a Models of Computation course is to teach students some basic machine types. It is common practice to input these machines interactively using a graphical tool such as JFLAP, and to view their simulation results also in the same graphical environment.\n",
    "\n",
    "Graphical interactions are powerful and intuitive. They provide powerful visual cues that tell a student how the machines \"work\" in the sense of chugging along, should they be built.\n",
    "\n",
    "However, a __graphics-only__ presentation for a machine typically studied in such a course is woefully deficient in two ways:\n",
    "\n",
    "1. It does not really allow a user to write programs for these complex machines. Programs that are purely presented as pictures \n",
    " \n",
    " a. quickly get cluttered\n",
    " \n",
    " b. quickly become a sphagetti of edges, circles, and edge labels that bump into other graphical elements\n",
    " \n",
    "2. It does not allow us to write comments. Without comments:\n",
    "\n",
    " a. Others (and even the original authors) will find it difficult to understand their construction\n",
    " \n",
    " b. Critical structures such as loops cannot be adequately documented, unless one has a textual representation\n",
    " \n",
    "In a nutshell, leaving complex machine constructions as pictures alone can lead to constructions that go wrong more often than they would emerge right. Even everyday things such as sending a machine description to someone becomes a chore. Automated grading is that much more clumsy: one needs the graphical environment around.\n",
    "\n",
    "We prefer a textual input method for these machines, from which graphical drawings can be easily produced. More specifically, we devise a __markdown__ language for DFA, NFA, PDA and TM. Our language is called the \"automd\" language standing for \"automata markdown\".\n",
    "\n",
    "A markdown approach has both advantages, namely:\n",
    "\n",
    "* One gets the program in textual form with comments\n",
    "\n",
    "* One can _also_ generate a drawing very easily, thus preserving most of the advantages (if not all) of a picture-only input method\n",
    "\n",
    "* In future, we can convert our markdowns to inputs to programs such as JFLAP\n",
    "\n",
    "In our tool suite, we don't have a full graphical simulation output at this point. However, we do provide sufficiently rich textual outputs that adequately capture simulations. (These facilities are easy to extend based on user-feedback.)\n",
    "\n",
    "## Markdown processing\n",
    "\n",
    "We define a single function md2mc() with arguments to be elaborated soon, but basically being the markdown input. This function produces an internal representation for the described machine (as a Python dictionary). This representation can be rendered as a drawing as well as simulated. \n",
    "\n",
    "We now describe how these are accomplished. Examples may be found in Jupyter notes Drive_md2mc. We now informally describe our markdown grammar and also provide its formal BNF grammar. (Incidentally, the markdown compiler forms a fantastic example that is worth studying. It has a regular grammar, but we use context-free productions to easily handle its constructs.)\n",
    "\n",
    "# Markdown grammar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Markdown code structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import sys\n",
    "\n",
    "#---- Leave these definitions ON if running on laptop\n",
    "#---- Else turn OFF by putting them between ''' ... '''\n",
    "\n",
    "sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
    "                 '../../../..',  '../../../../3rdparty',  \n",
    "                 '../../..',     '../../../3rdparty', \n",
    "                 '../..',        '../../3rdparty',\n",
    "\t\t '..',           '../3rdparty' ]\n",
    "\n",
    "\n",
    "from lex import lex\n",
    "from yacc import yacc \n",
    " \n",
    "#---- Turn these definitions ON if running on COLAB by removing ''' ... '''\n",
    "#---- Else leave them OFF\n",
    "\n",
    "'''\n",
    "! if [ ! -d Jove ]; then git clone https://github.com/anon-Jove/Jove Jove; fi\n",
    "import sys\n",
    "sys.path.append('./Jove')\n",
    "sys.path.append('./Jove/jove')\n",
    "\n",
    "from lex import lex\n",
    "from yacc import yacc \n",
    " \n",
    "#display(HTML('<link rel=\"stylesheet\" href=\"//stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"/>'))\n",
    "'''\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "#=================================================================\n",
    "# Maintain our own LINENO for error reporting \n",
    "# This is incremented by \\n, and reset to -1 after successful parsing \n",
    "# \"Successful parsing\" also includes the case of matching an error token\n",
    "#  (see the production rule p_you_are_hosed below)\n",
    "\n",
    "LINENO   = -1  \n",
    "reserved = {\n",
    "   'NFA' : 'NFA', \n",
    "   'DFA' : 'DFA', \n",
    "   'PDA' : 'PDA', \n",
    "   'TM'  : 'TM' \n",
    "}\n",
    "   \n",
    "def t_ID(t):\n",
    "    r'[a-zA-Z0-9#$%&()*+/=?@\\[\\\\\\]^_{}~]+'\n",
    "    # Printable ASCII sans space,  quotations ` ' \" and . : , ; - > < | !\n",
    "    # See https://docs.python.org/3/howto/regex.html for Python Regex\n",
    "    # See https://en.wikipedia.org/wiki/ASCII for printable ASCII\n",
    "    t.type = reserved.get(t.value,'ID') # default is 'ID'\n",
    "    return t\n",
    "\n",
    "tokens = ['EPS', 'BLANK', 'COLON', 'COMMA', 'SEMICOLON', 'ARROW', \n",
    "          'OR', 'ID'] + list(reserved.values())\n",
    "\n",
    "t_EPS    = r'\\'\\'|\\\"\\\"'  # No longer allowing @ as epsilon\n",
    "t_BLANK  = r'.'   \n",
    "t_COLON  = r'\\:'\n",
    "t_COMMA  = r'\\,'\n",
    "t_SEMICOLON = r'\\;'\n",
    "t_ARROW  = r'\\-\\>'\n",
    "t_OR     = r'\\|'\n",
    "\n",
    "# Ignored characters\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "def t_NEWLINE(t):\n",
    "    r'\\n+'\n",
    "    global LINENO\n",
    "    if LINENO==-1:\n",
    "        LINENO = 2\n",
    "    else:\n",
    "        LINENO += 1\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "\n",
    "# Strip user comments in input file, as described in\n",
    "# http://www.eng.utah.edu/~cs3100/lectures/l14/ply-3.4/doc/ply.html\n",
    "def t_COMMENT(t):\n",
    "    r'\\!\\!.*'\n",
    "    pass\n",
    "    # No return value. Token discarded\n",
    "    \n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "    \n",
    "# Build the lexer before calling yacc() below\n",
    "# Feed the lexer into the parser (see below)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Define data structures to hold semantic attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#=================================================================\n",
    "# Function default_line_attr() generates an empty attribute-structure\n",
    "# that is filled while parsing.\n",
    "#\n",
    "# The 'NEED ORDER' below marks those entities that collect items\n",
    "# from one line of markdown input HAVING TO preserve positional order.\n",
    "#\n",
    "# Example: in S : a,b ; c | d,e ; f -> G\n",
    "#  we go  S : a,b;c -> G   and   S : d,e;f -> G .\n",
    "# That is, \"a goes with b and c\", and not that \"a goes with e and f\".\n",
    "#\n",
    "# Since some entities demand order preservation, turn ALL of them into \n",
    "# lists, so that our coding becomes more uniform.\n",
    "\n",
    "def default_line_attr():\n",
    "    \"\"\"Used in virtually all p_.. rules in the parser.\n",
    "       ---\n",
    "       Default empty attribute that can be populated as we parse.\n",
    "       Here is how we fill the fields.\n",
    "       \n",
    "       For DFA, NFA, PDA, and TM:\n",
    "       - The 'from' state goes into \"FromState\".\n",
    "       - The 'to' states go into \"ToStates\".\n",
    "       - The input Sigma or Eps go into \"SigmaEps\".\n",
    "       \n",
    "       For PDA and TM:\n",
    "       - The input Gamma or Eps go into \"GammaIn\".\n",
    "       - The output Gamma goes into \"GammaOut\".\n",
    "       \n",
    "       For PDA, note that GammaOut can have strings > 1 in len.\n",
    "    \"\"\"\n",
    "    return {\"FromState\" : [], # Always singleton, per line of markdown\n",
    "            \"ToStates\"  : [], # Singleton (per line of markdown) for DFA\n",
    "            \"GammaIn\"   : [], # NEED ORDER; Single Gamma symbol or Eps\n",
    "            \"GammaOut\"  : [], # NEED ORDER; Gamma STRING for PDA\n",
    "            \"HeadDirn\"  : [], # NEED ORDER; Head direction STRING for TM\n",
    "            \"Q0\"        : [], # This field ends up singleton (barring NFA)\n",
    "            \"F\"         : [], # No restrictions\n",
    "            \"SigmaEps\"  : []  # NEED ORDER; Eps not for DFA\n",
    "           }\n",
    "\n",
    "from functools import reduce\n",
    "#=================================================================\n",
    "# length_ok_input_items()\n",
    "# * Sigma and Gamma_in must be of length <= 1\n",
    "# * Gamma_out for PDA is allowed to be longer (multi-symbol push)\n",
    "# * All other Gamma_out also of length <= 1\n",
    "#\n",
    "def length_ok_input_items(items):\n",
    "    \"\"\"Helper for union_line_attr_list_fld()\n",
    "       ---\n",
    "       Takes a list of items (grabbed from the attribute structure) and \n",
    "       ensures that the user input-items per markdown line are of length \n",
    "       1. This check is needed for Sigma, G_in, and G_out for TMs.  \n",
    "       However, G_out for PDAs can be of any length, so this checks \n",
    "       skips PDA.\n",
    "    \"\"\"\n",
    "    for item in items:\n",
    "        if len(item) != 1 and item != \"\":\n",
    "            print(\"Erroneous item -> \", item, \" <- during parsing : \")\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def union_line_attr_list_fld(line_attr_list, field, mc_type):\n",
    "    \"\"\"Helper for get_machine_components()\n",
    "       ---\n",
    "       Given a line_attr list and the name of a field, and a\n",
    "       machine type, check for errors, and then obtain the \n",
    "       union of those fields if all line_attr list members are OK.\n",
    "    \"\"\"\n",
    "    #-- Error checks.\n",
    "    assert(mc_type in {'DFA','NFA','PDA','TM'}\n",
    "          ),\"Error: Illegal machine type given: \" + mc_type\n",
    "    for line_attr in line_attr_list:\n",
    "        G_in  = line_attr[\"GammaIn\"]\n",
    "        G_out = line_attr[\"GammaOut\"]\n",
    "        Sigma = line_attr[\"SigmaEps\"]\n",
    "        #\n",
    "        #-- Epsilon-related checks. For TM, we customize error message...\n",
    "        #\n",
    "        if mc_type=='DFA':\n",
    "            assert(set({\"''\",'\"\"'})\n",
    "                   & set(Sigma) == set({})\n",
    "                  ),\"Error: DFA with an epsilon input illegal.\"\n",
    "        if mc_type=='TM':\n",
    "            assert(set({\"''\",'\"\"'}) \n",
    "                   & set(G_in) == set({})\n",
    "                ),\"Error: TM with epsilon input illegal. You meant '.'?\"\n",
    "            assert(set({\"''\",'\"\"'}) \n",
    "                   & set(G_out) == set({})\n",
    "                ),\"Error: TM with epsilon output illegal. You meant '.'?\"            \n",
    "        #\n",
    "        #-- Sigma, G_in and G_out related length checks\n",
    "        #-- for all items present, their lengths must be 1\n",
    "\n",
    "        assert(length_ok_input_items\n",
    "               (Sigma)\n",
    "              ),\"Error: Sigma contains a string longer than 1\"\n",
    "            \n",
    "        assert(length_ok_input_items\n",
    "               (G_in)\n",
    "              ),\"Error: G_in contains a string longer than 1\"\n",
    "        \n",
    "        if mc_type != 'PDA':\n",
    "            assert(length_ok_input_items\n",
    "                   (G_out)\n",
    "                  ),\"Error: G_out contains a string longer than 1\"\n",
    "                \n",
    "        #--end for\n",
    "\n",
    "        \n",
    "    #-- All checks pass. The reduce below might be fused with the for \n",
    "    #   above...\n",
    "    return reduce(lambda x,y: x+y, # list concat\n",
    "                  map(lambda line_attr: line_attr[field], line_attr_list),\n",
    "                  [])\n",
    "\n",
    "#=================================================================\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def extend_rsltdict(D, key, val, Extend=False):\n",
    "    \"\"\"Helper for form_delta()\n",
    "       ---\n",
    "       Given a result dictionary D, extend it, depending on\n",
    "       the setting of Boolean Extend. For some dictionaries,\n",
    "       duplicates mean \"extend\"; for others, that means error.\n",
    "       This is a crucial helper used by \"form_delta\".\n",
    "    \"\"\"\n",
    "    if Extend:\n",
    "        if key in D:\n",
    "            D[key] = D[key] | set({ val })\n",
    "        else:\n",
    "            D[key] = set({ val })\n",
    "    else:\n",
    "        assert(key not in D\n",
    "              ),(\"Error: Duplicate map at key \" + str(key) + \n",
    "                 \"; duplicates: \" + str(D[key]) + \" and \" + str(val)\n",
    "                )\n",
    "        D[key] = val # don't make a set\n",
    "    return D\n",
    "    \n",
    "    \n",
    "def form_delta(line_attr_list, mc_type):\n",
    "    \"\"\"Helper for get_machine_components()\n",
    "       ---\n",
    "       Given the machine type, cull the needed info from line_attr_list\n",
    "       and form the delta appropriate to the machine type.\n",
    "       \n",
    "       There are obviously many corner cases here! We discuss each \n",
    "       separately, taking pithy made-up examples from \n",
    "       DFA, NFA, PDA, and TM.  \n",
    "       \n",
    "       DFA/NFA: Given I : a | a -> P  \\n  I : a -> Q, \n",
    "                we form \n",
    "                (I,a) -> {P,Q}\n",
    "                \n",
    "                At the end, err for DFA saying we can't jump to \n",
    "                multiple targets. I.e., DFA can't jump to two states on \n",
    "                one input. (extend_rsltdict with Extend=False).\n",
    "                \n",
    "       PDA: Given I : a,b ; c | a,b ; d -> P,Q \\n I : a,b ; r -> R,\n",
    "            we form \n",
    "            (I, a, b) : { (c,P), (c,Q), (d,P), (d,Q), (r,R) } by\n",
    "            keeping a dict entry for (I, a, b), and extending that.\n",
    "                \n",
    "       TM:  Given I : a; b,c | a; b,d -> P,Q \\n I : a; b,r -> R,\n",
    "            we form \n",
    "            (I, a) : { (b,c,P), (b,c,Q), (b,d,P), (b,d,Q), (b,r,R) } \n",
    "            by keeping a dict entry for (I, a, b), and extending that.\n",
    "    \"\"\"\n",
    "    rslt_dict = dict({ })\n",
    "    #--\n",
    "    for attr in line_attr_list:\n",
    "        from_states = attr[\"FromState\"]\n",
    "        assert(len(from_states)==1\n",
    "              ),\"Error: More than one 'from-state' per markdown line.\"\n",
    "        from_state  = from_states[0]\n",
    "        #\n",
    "        sigeps_list = attr[\"SigmaEps\"]\n",
    "        G_in        = attr[\"GammaIn\"]\n",
    "        G_out       = attr[\"GammaOut\"]\n",
    "        to_states   = attr[\"ToStates\"]\n",
    "        head_dirn   = attr[\"HeadDirn\"]\n",
    "        #\n",
    "        if mc_type=='PDA':\n",
    "            assert(len(G_in)==len(G_out)\n",
    "                ),\"Error: PDA G_in/G_out lists are unequal in length.\"\n",
    "            assert(len(sigeps_list)==len(G_out)\n",
    "                ),\"Error: PDA SigmaEps/G_out lists are unequal in length.\"                \n",
    "            #\n",
    "            ziplab         = list(zip(sigeps_list, G_in, G_out))\n",
    "        elif mc_type=='TM':\n",
    "            assert(len(G_in)==len(G_out)\n",
    "                ),\"Error: TM G_in/G_out lists are unequal in length.\"\n",
    "            assert(len(head_dirn)==len(G_out)\n",
    "                ),\"Error: TM HeadDirn/G_out lists are unequal in length.\"\n",
    "            #\n",
    "            ziplab         = list(zip(G_in, G_out, head_dirn))\n",
    "        else:\n",
    "            assert(mc_type in {'NFA','DFA'}\n",
    "                  ),\"Error: Unknown machine type: \" + mc_type\n",
    "            ziplab         = sigeps_list\n",
    "        \n",
    "        # List of zipped labels paired with next states.\n",
    "        # From this, we have to form the transition-table key/value pairs.\n",
    "        # We call zipped labels paired with next states \"zl_nxtst\"\n",
    "        # and a list of them as l_zl_nxtst\n",
    "                 \n",
    "        l_zl_nxtst = product(ziplab, to_states)\n",
    "                 \n",
    "        # Now, we elaborate on l_zl_nxtst for various machine types:\n",
    "        #\n",
    "        # D/NFA: [ (in1,P), (in1,Q), (in2,Q) ]\n",
    "        # PDA  : [ ((in1, si1, sp1),P), ((in1,si1,sp2),P), \n",
    "        #           ((in1,si2,sp3),Q) .. ]\n",
    "        # TM   : [ ((ti1, to1,dir1),P), ((ti1,to2,dir2),P), \n",
    "        #           ((ti2,to3,dir3),Q) .. ]\n",
    "        #\n",
    "        for zl_nxtst in l_zl_nxtst:\n",
    "            if mc_type=='DFA':\n",
    "                # Prevent nondeterminism\n",
    "                (inpsym, nxtst) = zl_nxtst\n",
    "                rslt_dict = extend_rsltdict(rslt_dict,\n",
    "                                            (from_state, inpsym),\n",
    "                                            nxtst,\n",
    "                                            Extend=False)\n",
    "            elif mc_type=='NFA':\n",
    "                # Allow nondeterminism                \n",
    "                (inpsym, nxtst) = zl_nxtst\n",
    "                rslt_dict = extend_rsltdict(rslt_dict,\n",
    "                                            (from_state, inpsym),\n",
    "                                            nxtst,\n",
    "                                            Extend=True)\n",
    "            elif mc_type=='PDA':\n",
    "                # Allow nondeterminism\n",
    "                ((inpsym, stkpop, stkpush), nxtst) = zl_nxtst\n",
    "                rslt_dict = extend_rsltdict(rslt_dict,\n",
    "                                            (from_state, inpsym, stkpop),\n",
    "                                            (nxtst, stkpush),\n",
    "                                            Extend=True)\n",
    "            else:\n",
    "                assert(mc_type=='TM'\n",
    "                    ),\"Error: Illegal machine type supplied: \" + mc_type\n",
    "                ((tapein, tapeout, dirn), nxtst) = zl_nxtst\n",
    "                rslt_dict = extend_rsltdict(rslt_dict,\n",
    "                                            (from_state, tapein),\n",
    "                                            (nxtst, tapeout, dirn),\n",
    "                                            Extend=True)\n",
    "    #--\n",
    "    return rslt_dict\n",
    "\n",
    "\n",
    "#=================================================================\n",
    "\n",
    "def get_machine_components(line_attr_list, mc_type):\n",
    "    \"\"\"Used in four top-level parser rules, namely\n",
    "       p_dfa_md(), p_nfa_md(), p_pda_md() and p_tm_md()\n",
    "       ---\n",
    "       Given a list of line_attr dict items and mc_type\n",
    "       (which is one of 'DFA','NFA','PDA','TM'),\n",
    "       extract these components:\n",
    "       1) Q by unioning FromState and ToStates\n",
    "       2) Gamma by unioning GammaIn symbols and GammaOut strings\n",
    "       3) Q0 by unioning all Q0\n",
    "       4) F by unioning all F\n",
    "       5) Sigma by unioning all the SigmaEps sets, removing Eps\n",
    "       6) Eps by taking Eps from the set in 5\n",
    "\n",
    "       The formation of Delta is postponed till now. This is because\n",
    "       till now, we do not really know what machine-type we are dealing\n",
    "       with. So we will have to approach that within \n",
    "       union_line_attr_list_fld.\n",
    "    \"\"\"\n",
    "    # Given that we turned default_line_attr to all lists, we need to \"unique\"\n",
    "    # some of the lists formed here. We use list(set(L)) as we don't care\n",
    "    # about the order of many of these lists.\n",
    "    #\n",
    "    From_s = union_line_attr_list_fld(line_attr_list, \n",
    "                                      \"FromState\", mc_type)\n",
    "    To_s   = union_line_attr_list_fld(line_attr_list, \n",
    "                                      \"ToStates\", mc_type)\n",
    "    #    \n",
    "    G_in    = union_line_attr_list_fld(line_attr_list, \n",
    "                                       \"GammaIn\", mc_type)\n",
    "    G_out   = union_line_attr_list_fld(line_attr_list, \n",
    "                                       \"GammaOut\", mc_type)\n",
    "    #\n",
    "    Dirn    = union_line_attr_list_fld(line_attr_list, \n",
    "                                       \"HeadDirn\", mc_type)                                  \n",
    "    #    \n",
    "    Q0     = union_line_attr_list_fld(line_attr_list, \n",
    "                                      \"Q0\", mc_type)\n",
    "    #    \n",
    "    F      = union_line_attr_list_fld(line_attr_list, \n",
    "                                      \"F\", mc_type)\n",
    "    #    \n",
    "    Sigma  = union_line_attr_list_fld(line_attr_list, \n",
    "                                      \"SigmaEps\", mc_type)\n",
    "\n",
    "    Delta = form_delta(line_attr_list, mc_type)\n",
    "\n",
    "    return (set(From_s), set(To_s),\n",
    "            set(G_in),   set(G_out),\n",
    "            set(Q0),     set(F),\n",
    "            set(Sigma),  set(Dirn),\n",
    "            Delta)\n",
    "#=================================================================\n",
    "# Some simple extractors \n",
    "\n",
    "def is_init_st(id):\n",
    "    \"\"\"Used in p_one_line()\n",
    "       ---\n",
    "       Checks if id begins with i or I.\n",
    "    \"\"\"\n",
    "    return id[0] in {'i','I'}\n",
    "\n",
    "\n",
    "def is_fin_st(id):\n",
    "    \"\"\"Used in p_one_line()\n",
    "       ---\n",
    "       Checks if id begins with f or F or if or IF.\n",
    "    \"\"\"\n",
    "    return ( (id[0] in {'f','F'})\n",
    "             or ((len(id) > 1) and (id[0:2] == 'if' or id[0:2] == 'IF')) \n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Define the parsing rules now\n",
    "\n",
    "The first production is the \"top-level symbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#=================================================================\n",
    "# Rules for DFA, NFA, PDA, TM + error!\n",
    "# From the PLY manual: http://www.dabeaz.com/ply/ply.html#ply_nn28\n",
    "# Normally, the first rule found in a yacc specification defines the\n",
    "# starting grammar rule (top level rule). To change this,\n",
    "# simply supply a start specifier in your file.Rtt\n",
    "\n",
    "def p_you_are_hosed(t):\n",
    "    '''md : error'''\n",
    "    print(\"Your are hosed due to a syntax error!\")\n",
    "    global LINENO\n",
    "    LINENO = -1 # restore sanity wrt future reporting of errors\n",
    "    t[0] = ('ERROR', 'ERROR')\n",
    "    \n",
    "def p_dfa_md(t):\n",
    "    '''md : DFA lines'''\n",
    "    mc = get_machine_components(t[2], 'DFA')\n",
    "    (From_s, To_s,\n",
    "     G_in,   G_out,\n",
    "     Q0,     F,\n",
    "     Sigma,  Dirn, Delta) = mc\n",
    "    assert(len(Q0) == 1\n",
    "    ),\"Error: DFA with \" +str(len(Q0))+ \" starting states is illegal.\"\n",
    "    global LINENO\n",
    "    LINENO = -1 # restore for next error processing\n",
    "    t[0] = ('DFA', mc)\n",
    "    \n",
    "def p_nfa_md(t):\n",
    "    '''md : NFA lines'''\n",
    "    global LINENO\n",
    "    LINENO = -1 # restore for next error processing\n",
    "    t[0] = ('NFA', get_machine_components(t[2], 'NFA'))\n",
    "\n",
    "def p_pda_md(t):\n",
    "    '''md : PDA lines'''\n",
    "    mc = get_machine_components(t[2], 'PDA')\n",
    "    (From_s, To_s,\n",
    "     G_in,   G_out,\n",
    "     Q0,     F,\n",
    "     Sigma,  Dirn, Delta) = mc\n",
    "    assert(len(Q0) == 1),\"PDA with more than one starting state illegal.\"    \n",
    "    global LINENO\n",
    "    LINENO = -1 # restore for next error processing\n",
    "    t[0] = ('PDA', mc)\n",
    "    \n",
    "def p_tm_md(t):\n",
    "    '''md : TM lines'''\n",
    "    mc = get_machine_components(t[2], 'TM')\n",
    "    (From_s, To_s,\n",
    "     G_in,   G_out,\n",
    "     Q0,     F,\n",
    "     Sigma,  Dirn, Delta) = mc\n",
    "    assert(len(Q0) == 1\n",
    "          ),\"TM with more than one starting state illegal.\"\n",
    "    global LINENO\n",
    "    LINENO = -1 # restore for next error processing\n",
    "    t[0] = ('TM', mc)\n",
    "\n",
    "#=================================================================\n",
    "# lines for all machine types\n",
    "    \n",
    "def p_lines1(t):\n",
    "    '''lines : one_line'''\n",
    "    t[0] = [ t[1] ] # One line's attribute is a dict\n",
    "    \n",
    "def p_lines2(t):\n",
    "    '''lines : one_line lines'''\n",
    "    one_line_attr = [ t[1] ]\n",
    "    lines_attr    = t[2]\n",
    "    t[0] = one_line_attr + lines_attr # List of line attrs\n",
    "\n",
    "def p_one_line(t):\n",
    "    '''one_line : state COLON labels ARROW states'''\n",
    "    lineattr  = default_line_attr()\n",
    "    lineattr[\"FromState\"] = t[1]\n",
    "    lineattr[\"ToStates\"]  = t[5]\n",
    "    states_in_line        = t[1] + t[5]\n",
    "    #\n",
    "    lineattr[\"Q0\"]        = list(filter(is_init_st, states_in_line))\n",
    "    lineattr[\"F\"]         = list(filter(is_fin_st, states_in_line))\n",
    "    #\n",
    "    lineattr[\"SigmaEps\"]  = t[3][\"SigmaEps\"]\n",
    "    #\n",
    "    lineattr[\"GammaIn\"]   = t[3][\"GammaIn\"]\n",
    "    lineattr[\"GammaOut\"]  = t[3][\"GammaOut\"]\n",
    "    lineattr[\"HeadDirn\"]  = t[3][\"HeadDirn\"]    \n",
    "    #\n",
    "    t[0] = lineattr\n",
    "\n",
    "def p_state(t):\n",
    "    '''state : ID'''\n",
    "    t[0] = [ t[1] ]\n",
    "\n",
    "def p_states1(t):\n",
    "    '''states : state'''\n",
    "    t[0] = t[1] \n",
    "    \n",
    "def p_states2(t):\n",
    "    '''states : state COMMA states'''\n",
    "    t[0] = t[1] + t[3]\n",
    "\n",
    "def p_labels1(t):\n",
    "    '''labels : one_label'''\n",
    "    t[0] = t[1]\n",
    "    \n",
    "def p_labels2(t):\n",
    "    '''labels : one_label OR labels'''\n",
    "    # Combine SigmaEps, GammaIn, GammaOut, HeadDirn labels \n",
    "    # component-wise\n",
    "    L1 = t[1]\n",
    "    Ls = t[3]\n",
    "    lineattr = default_line_attr()\n",
    "    lineattr.update({ \"SigmaEps\": L1[\"SigmaEps\"] + Ls[\"SigmaEps\"] })                                   \n",
    "    lineattr.update({ \"GammaIn\" : L1[\"GammaIn\"]  + Ls[\"GammaIn\"]  })\n",
    "    lineattr.update({ \"GammaOut\": L1[\"GammaOut\"] + Ls[\"GammaOut\"] })\n",
    "    lineattr.update({ \"HeadDirn\": L1[\"HeadDirn\"] + Ls[\"HeadDirn\"] })\n",
    "    t[0] = lineattr\n",
    "\n",
    "# One label is a big deal. It deals with labels for DFA, NFA, PDA, or TM\n",
    "# A label for DFA and NFA are just ID_or_EPS\n",
    "# A label for a PDA is ID_or_EPS , One_gamma ; Many_Gammas\n",
    "# A label for a TM is  ID_or_B ; ID_or_B , ID  where the last ID is L,R,S\n",
    "def p_one_label1(t):\n",
    "    '''one_label : ID_or_EPS_or_B'''\n",
    "    t[0] = t[1]\n",
    "    \n",
    "def p_ID_or_EPS_or_B(t):\n",
    "    '''ID_or_EPS_or_B : ID\n",
    "                      | EPS\n",
    "                      | BLANK'''\n",
    "    id = t[1]\n",
    "    #--sanitize forms of epsilon after parsing\n",
    "    if id=='\"\"':\n",
    "        id = \"\"\n",
    "    elif id==\"''\":\n",
    "        id = ''\n",
    "    #--\n",
    "    lineattr = default_line_attr()\n",
    "    lineattr.update({ \"SigmaEps\" : [ id ] })\n",
    "    t[0] = lineattr\n",
    "\n",
    "def p_one_label2(t):\n",
    "    '''one_label : ID_or_EPS_or_B COMMA ID_or_EPS_or_B SEMICOLON ID_or_EPS_or_B'''\n",
    "    # t[1] is input symbol for PDA, that would already have \n",
    "    # climbed into SigmaEps.\n",
    "    #\n",
    "    # t[3] is stack-pop symbol for PDA\n",
    "    # t[5] is stack-push string for PDA\n",
    "    #\n",
    "    # We can take t[1] and update it to carry\n",
    "    # GammaIn coming in via t[3], and\n",
    "    # GammaOut coming in via t[5].\n",
    "    #\n",
    "    lineattr = t[1]\n",
    "    lineattr.update({ \"GammaIn\" : t[3][\"SigmaEps\"]  })\n",
    "    lineattr.update({ \"GammaOut\": t[5][\"SigmaEps\"] })\n",
    "    t[0] = lineattr\n",
    "\n",
    "def dirn_is_ok(dirn):\n",
    "    \"\"\"Ensure that the TM head direction is OK.\n",
    "    \"\"\"\n",
    "    return dirn in set({'L','R','S'})\n",
    "\n",
    "def p_one_label3(t):\n",
    "    '''one_label : ID_or_EPS_or_B SEMICOLON ID_or_EPS_or_B COMMA ID_or_EPS_or_B'''        \n",
    "    # t[1] is input symbol for TM, that would already have \n",
    "    # climbed into SigmaEps.\n",
    "    #\n",
    "    # It also belongs to GammaIn, so fix that up too.\n",
    "    #\n",
    "    # t[3] is tape-write symbol for TM\n",
    "    # t[5] is direction for TM\n",
    "    #\n",
    "    # We can take t[1] and update it to carry\n",
    "    # GammaOut coming in via t[3].\n",
    "    # We can check for t[5] being L,R,S.\n",
    "    #\n",
    "    lineattr = t[1] # Contains the SigmaEps attribute coming in\n",
    "    lineattr.update({ \"GammaIn\" : lineattr[\"SigmaEps\"] }) #shift to G_in\n",
    "    lineattr.update({ \"GammaOut\": t[3][\"SigmaEps\"] })     #shift to G_out\n",
    "    #                                   \n",
    "    dirn_list = t[5][\"SigmaEps\"]\n",
    "    assert(len(dirn_list)==1), \"Direction specifier set has length > 1\"\n",
    "    assert(dirn_is_ok(dirn_list[0])),\"Illegal head-direction in TM!\"\n",
    "    #                                                                      \n",
    "    lineattr.update({ \"HeadDirn\" : dirn_list })\n",
    "    t[0] = lineattr\n",
    "    \n",
    "#=================================================================\n",
    "    \n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value, \" on line \", LINENO)\n",
    "    \n",
    "#=================================================================\n",
    "# End of all parsing rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# md2mc():  Function exported out of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def md2mc(src=\"None\", fname=\"None\"):\n",
    "    \"\"\"md2mc converts a markdown source to a machine (mc).\n",
    "    \n",
    "       One can feed the markdown in three ways, shown via \n",
    "       pseudo-examples:\n",
    "       \n",
    "       1) md2mc()\n",
    "       \n",
    "          It means you will provide a file-name\n",
    "          (you will be prompted for one). Then the markdown is read from\n",
    "          that file. \n",
    "          \n",
    "       2) md2mc(src=\"<any string S other than 'File'>\")\n",
    "       \n",
    "          S is now taken as the markdown string and parsed. This is \n",
    "          bound to be a multi-line file. \n",
    "          \n",
    "          There is a Jupyter bug that if the parser (or any process) \n",
    "          consuming a multi-line input throws an exception, you will get \n",
    "          a strange error message: \n",
    "          ERROR:root:An unexpected error occurred while tokenizing input\n",
    "          Ignore it please, and instead spend your time fixing the \n",
    "          markdown input. See for details:\n",
    "          https://github.com/ipython/ipython/issues/6864\n",
    "          \n",
    "          \n",
    "       3) md2mc(src=\"File\", fname=\"<your file name path>\")\n",
    "       \n",
    "          Obviously, you should not be feeding a markdown with contents \n",
    "          \"File\". It is not legit markdown syntax. So if src=\"File\", \n",
    "          then fname is taken to be the path-name to a file that is \n",
    "          opened and read.\n",
    "        \n",
    "       In all cases, the returned result is a machine structure (dict).\n",
    "    \"\"\"\n",
    "    if (src==\"None\"):\n",
    "        mdstr = open(input('File name ='), 'r').read()\n",
    "    elif (src==\"File\"):\n",
    "        mdstr = open(fname).read()\n",
    "    else:\n",
    "        mdstr = src\n",
    "    myparser = yacc()\n",
    "    mdlexer = lex()   # Build lexer custom-made for markdown\n",
    "    rslt = myparser.parse(mdstr, lexer=mdlexer) # feed into parse fn\n",
    "    #--\n",
    "    # Now, based on machine type, return correct machine object.\n",
    "    #--\n",
    "    (machine_type,\n",
    "     (From_s, To_s,\n",
    "      G_in,   G_out,\n",
    "      Q0,     F,\n",
    "      Sigma,  Dirn, Delta)) = rslt\n",
    "    #--\n",
    "    #-- for now, make struct right here; later call right maker\n",
    "    #--\n",
    "    if machine_type != 'NFA':\n",
    "        assert(len(Q0)==1)\n",
    "        q0 = list(Q0)[0]\n",
    "    if machine_type=='DFA':\n",
    "        return {\"Q\"    : From_s | To_s,\n",
    "                \"Sigma\": Sigma,\n",
    "                \"Delta\": Delta,\n",
    "                \"q0\"   : q0,\n",
    "                \"F\"    : F}\n",
    "    \n",
    "    elif machine_type=='NFA':\n",
    "        return {\"Q\"    : From_s | To_s,\n",
    "                \"Sigma\": Sigma - {'',\"\"},\n",
    "                \"Delta\": Delta,\n",
    "                \"Q0\"   : Q0,\n",
    "                \"F\"    : F}\n",
    "    \n",
    "    elif machine_type=='PDA':\n",
    "        G_out_set = reduce(lambda x,y: x|y, map(set, G_out), set({}))\n",
    "        return {\"Q\"    : From_s | To_s,\n",
    "                \"Sigma\": Sigma - {'',\"\"},\n",
    "                \"Gamma\": (G_in | G_out_set | {'#'} | Sigma) - {'',\"\"},\n",
    "                \"Delta\": Delta,\n",
    "                \"q0\"   : q0,\n",
    "                \"z0\"   : '#',   # Hash-mark is the new \"z0\" for a PDA!\n",
    "                \"F\"    : set(F)}\n",
    "    else: \n",
    "        assert(machine_type=='TM')\n",
    "        return {\"Q\"    : From_s | To_s,\n",
    "                \"Sigma\": Sigma - {'',\"\",'@','.'},\n",
    "                \"Gamma\": (G_in | G_out | {'.'} | Sigma) - {'',\"\",'@'},\n",
    "                \"Delta\": Delta,\n",
    "                \"q0\"   : q0,\n",
    "                \"B\"    : '.',\n",
    "                \"F\"    : F}        \n",
    "        \n",
    "    return rslt\n",
    "    \n",
    "#================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print('''You may use any of these help commands:\n",
    "help(md2mc)\n",
    ".. and if you want to dig more, then ..\n",
    "help(default_line_attr)\n",
    "help(length_ok_input_items)\n",
    "help(union_line_attr_list_fld)\n",
    "help(extend_rsltdict)\n",
    "help(form_delta)\n",
    "help(get_machine_components)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "This finishes our description of the md2mc module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
