{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "<span style=\"color:blue\"> **Chapter 5 of Jupyter Notes** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Regular Expressions, conversion to NFA\n",
    "\n",
    "In this module, we will cover regular expressions by showing how they can be converted to NFA. The scanner and parser for RE to convert them to NFA are the main part of this module.\n",
    "\n",
    "# Top-level functions in this module\n",
    "\n",
    "```\n",
    "This module contains the following functions that may be used in other modules to exercise concepts, compose functions, etc.\n",
    "\n",
    "s     : string\n",
    "\n",
    "Here are the functions\n",
    "\n",
    "def re2nfa(s, stno = 0):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import sys\n",
    "\n",
    "# -- Detect if in Own Install or in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    OWN_INSTALL = False\n",
    "except:\n",
    "    OWN_INSTALL = True\n",
    "    \n",
    "if OWN_INSTALL:\n",
    "    \n",
    "  #---- Leave these definitions ON if running on laptop\n",
    "  #---- Else turn OFF by putting them between ''' ... '''\n",
    "\n",
    "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
    "                   '../../../..',  '../../../../3rdparty',  \n",
    "                   '../../..',     '../../../3rdparty', \n",
    "                   '../..',        '../../3rdparty',\n",
    "                   '..',           '../3rdparty' ]\n",
    "\n",
    "else: # In colab\n",
    "  ! if [ ! -d Jove ]; then git clone https://github.com/anon-Jove/Jove Jove; fi\n",
    "  sys.path.append('./Jove')\n",
    "  sys.path.append('./Jove/jove')\n",
    "\n",
    "# -- common imports --\n",
    "from jove.DotBashers  import dotObj_dfa\n",
    "from jove.DotBashers  import dotObj_nfa\n",
    "\n",
    "from jove.Module4_NFA import nfa2dfa\n",
    "from jove.Module4_NFA import rev_dfa\n",
    "from jove.Module4_NFA import mk_nfa\n",
    "from jove.Module4_NFA import min_dfa_brz\n",
    "\n",
    "from jove.lex                 import lex\n",
    "from jove.yacc                import yacc\n",
    "from jove.StateNameSanitizers import ResetStNum, NxtStateStr\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Parsing regular expressions : ReParse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# reparseNEW.py\n",
    "#\n",
    "# Parses regular expressions (without the empty RE case)\n",
    "# Produces NFA as output.\n",
    "#\n",
    "# The NEW signifies that I'm generating NFAs starting from\n",
    "# sets of states.\n",
    "#\n",
    "# Adapted from calc.py that is available from \n",
    "# www.dabeaz.com/ply/example.html\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "#-- Begin lexer construction\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#-- The tokens that constitute an RE are these\n",
    "tokens = (\n",
    "    'EPS','STR','LPAREN','RPAREN','PLUS','STAR'\n",
    "    )\n",
    "\n",
    "#-- The token definitions in terms of raw strings are being expressed now\n",
    "t_PLUS    = r'\\+'\n",
    "t_STAR    = r'\\*'\n",
    "t_LPAREN  = r'\\('\n",
    "t_RPAREN  = r'\\)'\n",
    "t_EPS     = r'\\'\\'|\\\"\\\"'  # Not allowing @ for empty string anymore!\n",
    "t_STR     = r'[a-zA-Z0-9]'  \n",
    "# Making the above r'[a-zA-Z0-9]+' to accept strings as \n",
    "# \"tokens\", i.e. indivisible units that can be subject to\n",
    "# RE operations\n",
    "\n",
    "#-- Ignored characters by the lexer\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "#-- Upon new lines, increase the lexer's line count variable\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "\n",
    "#-- Lexer's error announcer for illegal characters\n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "    \n",
    "#-- NOW BUILD THE LEXER --\n",
    "lexer = lex()\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Here is the parser set-up in terms of binary operator attributes\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#--- This is a global - for name generation in parser\n",
    "NxtStateNum = 0 \n",
    "def NxtStateStr():\n",
    "    global NxtStateNum\n",
    "    NxtStateNum += 1\n",
    "    return \"St\"+str(NxtStateNum)\n",
    "\n",
    "#-- Token precedences and associativity are declared in one place\n",
    "#-- By declaring PLUS before STAR, we are implying that it's of lower \n",
    "#-- precedence. Also declared is that they are both left-associative.\n",
    "\n",
    "precedence = (\n",
    "    ('left','PLUS'),\n",
    "    ('left','STAR'),\n",
    "    )\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#--- Here are the parsing rules for REs; each returns an NFA as \"code\"\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#-- * The E -> E + C production\n",
    "\n",
    "def p_expression_plus(t):\n",
    "    '''expression : expression PLUS catexp'''\n",
    "    t[0] = mk_plus_nfa(t[1], t[3]) # Union of the two NFAs is returned\n",
    "    \n",
    "def mk_plus_nfa(N1, N2):\n",
    "    \"\"\"Given two NFAs, return their union.\n",
    "    \"\"\"\n",
    "    delta_accum = dict({})\n",
    "    delta_accum.update(N1[\"Delta\"])\n",
    "    delta_accum.update(N2[\"Delta\"]) # Simply accumulate the transitions\n",
    "    # The alphabet is inferred bottom-up; thus we must union the Sigmas \n",
    "    # of the NFAs!\n",
    "    return mk_nfa(Q     = N1[\"Q\"] | N2[\"Q\"], \n",
    "                  Sigma = N1[\"Sigma\"] | N2[\"Sigma\"], \n",
    "                  Delta = delta_accum, \n",
    "                  Q0    = N1[\"Q0\"] | N2[\"Q0\"], \n",
    "                  F     = N1[\"F\"] | N2[\"F\"])    \n",
    "\n",
    "#-- * The E -> C production\n",
    "    \n",
    "def p_expression_plus_id(t):\n",
    "    '''expression : catexp'''\n",
    "    # Simply inherit the attribute from t[1] and pass on    \n",
    "    t[0] = t[1] \n",
    "\n",
    "#-- * The C -> C O production\n",
    "\n",
    "def p_expression_cat(t):\n",
    "    '''catexp :  catexp ordyexp'''\n",
    "    t[0] = mk_cat_nfa(t[1], t[2])\n",
    "\n",
    "def mk_cat_nfa(N1, N2):\n",
    "    delta_accum = dict({}) \n",
    "    delta_accum.update(N1[\"Delta\"])\n",
    "    delta_accum.update(N2[\"Delta\"])\n",
    "    # Now, introduce moves from every one of N1's final states\n",
    "    # to the set of N2's initial states.\n",
    "    for f in N1[\"F\"]:\n",
    "        # However, N1's final states may already have epsilon moves to\n",
    "        # other N1-states!\n",
    "        # Expand the target of such jumps to include N2's Q0 also!\n",
    "        if (f, \"\") in N1[\"Delta\"]: \n",
    "            delta_accum.update({ (f,\"\"):(N2[\"Q0\"] | N1[\"Delta\"][(f, \"\")])\n",
    "                               })\n",
    "        else:\n",
    "            delta_accum.update({ (f, \"\"): N2[\"Q0\"] })\n",
    "    # In syntax-directed translation, it is impossible\n",
    "    # that N2 and N1 have common states. Check anyhow\n",
    "    # in case there are bugs elsewhere that cause it.\n",
    "    assert((N2[\"F\"] & N1[\"F\"]) == set({})) \n",
    "    return mk_nfa(Q     = N1[\"Q\"] | N2[\"Q\"], \n",
    "                  Sigma = N1[\"Sigma\"] | N2[\"Sigma\"], \n",
    "                  Delta = delta_accum, \n",
    "                  Q0    = N1[\"Q0\"],\n",
    "                  F     = N2[\"F\"])\n",
    "\n",
    "#-- * The C -> O production\n",
    "\n",
    "def p_expression_cat_id(t):\n",
    "    '''catexp :  ordyexp'''\n",
    "    # Simply inherit the attribute from t[1] and pass on\n",
    "    t[0] = t[1]\n",
    "\n",
    "#-- * The O -> O STAR production\n",
    "\n",
    "def p_expression_ordy_star(t):\n",
    "    'ordyexp : ordyexp STAR'\n",
    "    t[0] = mk_star_nfa(t[1])\n",
    "\n",
    "def mk_star_nfa(N):\n",
    "    # Follow construction from Kozen's book:\n",
    "    # 1) Introduce new (single) start+final state IF\n",
    "    # 2) Let Q0 = set({ IF })\n",
    "    # 2) Move on epsilon from IF to the set N[Q0]\n",
    "    # 3) Make N[F] non-final\n",
    "    # 4) Spin back from every state in N[F] to Q0\n",
    "    #\n",
    "    delta_accum = dict({})\n",
    "    IF = NxtStateStr()\n",
    "    Q0 = set({ IF }) # new set of start + final states\n",
    "    # Jump from IF to N's start state set\n",
    "    delta_accum.update({ (IF,\"\"): N[\"Q0\"] })\n",
    "    delta_accum.update(N[\"Delta\"])\n",
    "    #\n",
    "    for f in N[\"F\"]:\n",
    "        # N's final states may already have epsilon moves to\n",
    "        # other N-states!\n",
    "        # Expand the target of such jumps to include Q0 also.\n",
    "        if (f, \"\") in N[\"Delta\"]:\n",
    "            delta_accum.update({ (f, \"\"): (Q0 | N[\"Delta\"][(f, \"\")]) })\n",
    "        else:\n",
    "            delta_accum.update({ (f, \"\"): Q0 })\n",
    "    #\n",
    "    return mk_nfa(Q     = N[\"Q\"] | Q0, \n",
    "                  Sigma = N[\"Sigma\"], \n",
    "                  Delta = delta_accum, \n",
    "                  Q0    = Q0, \n",
    "                  F     = Q0)\n",
    "\n",
    "#-- * The O -> ( E ) production\n",
    "\n",
    "def p_expression_ordy_paren(t):\n",
    "    'ordyexp : LPAREN expression RPAREN'\n",
    "    # Simply inherit the attribute from t[2] and pass on\n",
    "    t[0] = t[2]\n",
    "\n",
    "#-- * The O -> EPS production\n",
    "    \n",
    "def p_expression_ordy_eps(t):\n",
    "    'ordyexp : EPS'\n",
    "    t[0] = mk_eps_nfa()\n",
    "\n",
    "def mk_eps_nfa():\n",
    "    \"\"\"An nfa with exactly one start+final state\n",
    "    \"\"\"\n",
    "    Q0 = set({ NxtStateStr() })\n",
    "    F  = Q0\n",
    "    return mk_nfa(Q     = Q0, \n",
    "                  Sigma = set({}), \n",
    "                  Delta = dict({}), \n",
    "                  Q0    = Q0, \n",
    "                  F     = Q0)                      \n",
    "\n",
    "#-- * The O -> STR production, i.e. a single re letter\n",
    "\n",
    "def p_expression_ordy_str(t):\n",
    "    'ordyexp : STR'\n",
    "    t[0] = mk_symbol_nfa(t[1])\n",
    "\n",
    "def mk_symbol_nfa(a):\n",
    "    \"\"\"The NFA for a single re letter\n",
    "    \"\"\"\n",
    "    # Make a fresh initial state\n",
    "    q0 = NxtStateStr()\n",
    "    Q0 = set({ q0 })\n",
    "    # Make a fresh final state\n",
    "    f = NxtStateStr()\n",
    "    F = set({ f })\n",
    "    return mk_nfa(Q     = Q0 | F, \n",
    "                  Sigma = set({a}), \n",
    "                  Delta = { (q0,a): F },\n",
    "                  Q0    = Q0, \n",
    "                  F     = F)\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "#-- NOW BUILD THE PARSER --    \n",
    "parser = yacc()\n",
    "\n",
    "# End of reparseNEW.py\n",
    "# -----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## RE to NFA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def re2nfa(s, stno = 0):\n",
    "    \"\"\"Given a string s representing an RE and an optional\n",
    "       state number stno (default 0), generate an NFA that\n",
    "       is language equivalent to the RE\n",
    "    \"\"\"\n",
    "    # Reset the state number generator to 0\n",
    "    ResetStNum() \n",
    "    # NxtStateStr() gets called whenever needed. \n",
    "    # Defined in StateNameSanitizers.py\n",
    "\n",
    "    relexer = lex()\n",
    "\n",
    "    #-- NOW BUILD THE PARSER -- \n",
    "    reparser = yacc()\n",
    "    #-- FEED IT THE LEXER --\n",
    "    myparsednfa = reparser.parse(s, lexer=relexer)\n",
    "    #-- for debugging : return dotObj_nfa(myparsednfa, nfaname)\n",
    "    return myparsednfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "re2nfa(\"(bb*+cc)(c+d*)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"aa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"a*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"aa*+ab*\"), \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "re2nfa(\"(aa*+ab*)*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "re2nfa(\"a*b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "re2nfa(\"(a*b)*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "re2nfa(\"a*b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "astarbnfa = re2nfa(\"a*b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(astarbnfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(astarbnfa, visible_eps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "astarbdfa = nfa2dfa(astarbnfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_dfa(astarbdfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rev_dfa(astarbdfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_dfa(min_dfa_brz(nfa2dfa(re2nfa(\"(a+b)*a(a+b)(a+b)\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_dfa(nfa2dfa(re2nfa(\"(b*+ba*)*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"''*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"''*\"), visible_eps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dotObj_nfa(re2nfa(\"(apple+orange)*\"), visible_eps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "source": [
    "If you want to have some fun, change the STR RE to have  \"+\" at the end, as recommended in the comments below t_STR (early part of these notes). Then you can accept \"apple\" as a single token."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
